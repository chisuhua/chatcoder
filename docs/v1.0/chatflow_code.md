# ChatFlow v1.0 åŸºç¡€ä»£ç æ¡†æ¶

ä»¥ä¸‹æ˜¯ä¸º **ä¸ªäººå¼€å‘ç¯å¢ƒã€å¤šPythonæ¨¡å—å…±äº«ã€è½»é‡çº§å•æœºè¿è¡Œ** åœºæ™¯è®¾è®¡çš„ v1.0 ç‰ˆæœ¬å®Œæ•´åŸºç¡€æ¡†æ¶ã€‚ä»£ç ç®€æ´ã€æ— å¤–éƒ¨ä¾èµ–ï¼ˆé™¤æ ‡å‡†åº“ï¼‰ï¼Œæ”¯æŒè¿›ç¨‹å†…å¤šæ¨¡å—å®‰å…¨åä½œã€‚

---

## ğŸ“ é¡¹ç›®ç»“æ„
```bash
chatflow/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ engine.py          # æ ¸å¿ƒå¼•æ“
â”‚   â””â”€â”€ models.py          # æ•°æ®æ¨¡å‹
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ file_state_store.py # æ–‡ä»¶å­˜å‚¨å®ç°
â”‚   â””â”€â”€ file_lock.py       # æ–‡ä»¶é”å·¥å…·
â””â”€â”€ utils/
    â””â”€â”€ id_generator.py    # IDç”Ÿæˆå·¥å…·
```

---

## âœ… `chatflow/utils/id_generator.py`
```python
# chatflow/utils/id_generator.py
import uuid
import time

def generate_id() -> str:
    """ç”ŸæˆçŸ­å”¯ä¸€ID"""
    return uuid.uuid4().hex[:12]

def generate_timestamp() -> float:
    """è·å–æ—¶é—´æˆ³"""
    return time.time()
```

---

## âœ… `chatflow/core/models.py`
```python
# chatflow/core/models.py
from dataclasses import dataclass, field
from datetime import datetime
from typing import Dict, List, Optional

@dataclass
class HistoryEntry:
    phase: str
    task: str
    started_at: float
    ended_at: Optional[float] = None
    status: str = "running"  # running, completed, failed
    trigger_data_snapshot: Optional[Dict] = None

@dataclass
class TaskExecutionRecord:
    phase_name: str
    status: str
    started_at: float
    ended_at: Optional[float] = None
    prompt_checksum: str = ""
    response_checksum: str = ""

@dataclass
class WorkflowInstanceState:
    instance_id: str
    feature_id: str
    workflow_name: str
    current_phase: str
    variables: Dict
    status: str = "created"  # created, running, completed, failed
    history: List[HistoryEntry] = field(default_factory=list)
    created_at: float = field(default_factory=generate_timestamp)
    updated_at: float = field(default_factory=generate_timestamp)
    meta: Dict = field(default_factory=dict)  # ç”¨äºé€ä¼ ä¸Šä¸‹æ–‡
```

---

## âœ… `chatflow/storage/file_lock.py`
```python
# chatflow/storage/file_lock.py
import fcntl
import os
from pathlib import Path

class FileLock:
    """è·¨è¿›ç¨‹æ–‡ä»¶é”"""
    
    def __init__(self, lock_file_path: str):
        self.lock_file_path = Path(lock_file_path)
        
    def __enter__(self):
        self.lock_file_path.parent.mkdir(parents=True, exist_ok=True)
        self._lock_file = open(self.lock_file_path, "w")
        fcntl.flock(self._lock_file.fileno(), fcntl.LOCK_EX)
        return self
        
    def __exit__(self, *args):
        fcntl.flock(self._lock_file.fileno(), fcntl.LOCK_UN)
        self._lock_file.close()
```

---

## âœ… `chatflow/storage/file_state_store.py`
```python
# chatflow/storage/file_state_store.py
import json
import hashlib
from pathlib import Path
from typing import Dict, List, Optional
from .file_lock import FileLock
from ..core.models import WorkflowInstanceState, TaskExecutionRecord
from ...utils.id_generator import generate_timestamp

class IWorkflowStateStore:
    """çŠ¶æ€å­˜å‚¨æ¥å£"""
    
    def save_state(self, instance_id: str, state_data: Dict):
        raise NotImplementedError
        
    def load_state(self, instance_id: str) -> Optional[Dict]:
        raise NotImplementedError
        
    def list_instances_by_feature(self, feature_id: str) -> List[str]:
        raise NotImplementedError
        
    def save_task_artifacts(
        self,
        feature_id: str,
        instance_id: str,
        phase_name: str,
        task_record_data: Dict,
        prompt_content: str,
        ai_response_content: str
    ):
        raise NotImplementedError


class FileStateStore(IWorkflowStateStore):
    """åŸºäºæ–‡ä»¶ç³»ç»Ÿçš„çŠ¶æ€å­˜å‚¨"""
    
    def __init__(self, base_dir: str = ".chatflow"):
        self.base_dir = Path(base_dir).resolve()
        self.instances_dir = self.base_dir / "instances"
        self.features_dir = self.base_dir / "features"
        self.locks_dir = self.base_dir / ".locks"
        
        for dir_path in [self.instances_dir, self.features_dir, self.locks_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
    
    def _get_instance_file(self, instance_id: str) -> Path:
        return self.instances_dir / f"{instance_id}.json"
    
    def _get_instance_tasks_dir(self, instance_id: str) -> Path:
        tasks_dir = self.instances_dir / instance_id / "tasks"
        tasks_dir.mkdir(parents=True, exist_ok=True)
        return tasks_dir
    
    def _compute_checksum(self, content: str) -> str:
        if not content:
            return ""
        return hashlib.sha256(content.encode()).hexdigest()
    
    def save_state(self, instance_id: str, state_data: Dict):
        instance_file = self._get_instance_file(instance_id)
        with FileLock(str(self.locks_dir / f"{instance_id}.lock")):
            # åŸå­å†™å…¥
            temp_file = instance_file.with_suffix(".json.tmp")
            temp_file.write_text(json.dumps(state_data, indent=2), encoding="utf-8")
            temp_file.rename(instance_file)
            
            # æ›´æ–°ç‰¹æ€§ç´¢å¼•
            feature_index = self.features_dir / f"{state_data['feature_id']}.link"
            with FileLock(str(self.locks_dir / "features.lock")):
                current = set()
                if feature_index.exists():
                    content = feature_index.read_text().strip()
                    current = set(content.split(",") if content else [])
                current.add(instance_id)
                feature_index.write_text(",".join(sorted(current)))
    
    def load_state(self, instance_id: str) -> Optional[Dict]:
        instance_file = self._get_instance_file(instance_id)
        with FileLock(str(self.locks_dir / f"{instance_id}.lock")):
            if instance_file.exists():
                try:
                    content = instance_file.read_text(encoding="utf-8")
                    return json.loads(content)
                except (IOError, json.JSONDecodeError):
                    pass
        return None
    
    def list_instances_by_feature(self, feature_id: str) -> List[str]:
        index_file = self.features_dir / f"{feature_id}.link"
        if index_file.exists():
            content = index_file.read_text().strip()
            return [iid.strip() for iid in content.split(",") if iid.strip()]
        return []
    
    def save_task_artifacts(
        self,
        feature_id: str,
        instance_id: str,
        phase_name: str,
        task_record_data: Dict,
        prompt_content: str,
        ai_response_content: str
    ):
        tasks_dir = self._get_instance_tasks_dir(instance_id)
        base_name = phase_name.replace(" ", "_").lower()
        
        # ä¿å­˜å…ƒæ•°æ®
        record_file = tasks_dir / f"{base_name}.json"
        record_file.write_text(json.dumps(task_record_data, indent=2))
        
        # ä¿å­˜æ–‡æœ¬äº§ç‰©
        prompt_file = tasks_dir / f"{base_name}.prompt.md"
        response_file = tasks_dir / f"{base_name}.ai_response.md"
        
        prompt_file.write_text(prompt_content)
        response_file.write_text(ai_response_content)
```

---

## âœ… `chatflow/core/engine.py`
```python
# chatflow/core/engine.py
import threading
from typing import Dict, Optional, List
from dataclasses import asdict
from .models import WorkflowInstanceState, HistoryEntry, TaskExecutionRecord
from ..storage.file_state_store import FileStateStore, IWorkflowStateStore
from ...utils.id_generator import generate_id, generate_timestamp

class IWorkflowEngine:
    """å·¥ä½œæµå¼•æ“æ¥å£"""
    
    def start_workflow_instance(
        self,
        workflow_schema: Dict,
        initial_context: Dict,
        feature_id: str,
        meta: Optional[Dict] = None
    ) -> str:
        raise NotImplementedError
    
    def trigger_next_step(
        self,
        instance_id: str,
        trigger_data: Optional[Dict] = None,
        meta: Optional[Dict] = None
    ) -> WorkflowInstanceState:
        raise NotImplementedError
    
    def get_workflow_instance_status(
        self,
        instance_id: str
    ) -> Optional[WorkflowInstanceState]:
        raise NotImplementedError
    
    def get_feature_status(
        self,
        feature_id: str,
        schema_name: str = "default"
    ) -> Dict:
        raise NotImplementedError


class WorkflowEngine(IWorkflowEngine):
    """
    è¿›ç¨‹çº§å•ä¾‹å·¥ä½œæµå¼•æ“
    å¤šä¸ªæ¨¡å—å¯¼å…¥æ—¶å…±äº«åŒä¸€å®ä¾‹
    """
    
    _instance = None
    _lock = threading.RLock()
    
    def __init__(
        self,
        storage_dir: str = ".chatflow",
        state_store: IWorkflowStateStore = None
    ):
        if not hasattr(self, 'initialized'):
            with self._lock:
                if not hasattr(self, 'initialized'):
                    self.state_store = state_store or FileStateStore(storage_dir)
                    self._state_cache = {}  # {instance_id: (instance, timestamp)}
                    self.initialized = True
    
    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def _get_from_cache(self, instance_id: str) -> Optional[WorkflowInstanceState]:
        if instance_id in self._state_cache:
            instance, timestamp = self._state_cache[instance_id]
            if generate_timestamp() - timestamp < 30:  # 30ç§’TTL
                return instance
            else:
                del self._state_cache[instance_id]
        return None
    
    def _put_in_cache(self, instance_id: str, instance: WorkflowInstanceState):
        self._state_cache[instance_id] = (instance, generate_timestamp())
    
    def _clear_cache(self, instance_id: str):
        self._state_cache.pop(instance_id, None)
    
    def start_workflow_instance(
        self,
        workflow_schema: Dict,
        initial_context: Dict,
        feature_id: str,
        meta: Optional[Dict] = None
    ) -> str:
        with self._lock:
            instance_id = f"wfi_{generate_id()}"
            workflow_name = workflow_schema.get("name", "default")
            
            # ç¡®å®šèµ·å§‹é˜¶æ®µ
            phases = workflow_schema.get("phases", [])
            initial_phase = phases[0]["name"] if phases else "unknown"
            
            instance = WorkflowInstanceState(
                instance_id=instance_id,
                feature_id=feature_id,
                workflow_name=workflow_name,
                current_phase=initial_phase,
                variables=initial_context.copy(),
                status="created",
                meta=meta or {}
            )
            
            self.state_store.save_state(instance_id, asdict(instance))
            self._put_in_cache(instance_id, instance)
            
            return instance_id
    
    def trigger_next_step(
        self,
        instance_id: str,
        trigger_data: Optional[Dict] = None,
        meta: Optional[Dict] = None
    ) -> WorkflowInstanceState:
        with self._lock:
            # åŠ è½½å½“å‰çŠ¶æ€
            cached = self._get_from_cache(instance_id)
            if cached:
                instance = cached
            else:
                state_data = self.state_store.load_state(instance_id)
                if not state_data:
                    raise ValueError(f"Instance {instance_id} not found")
                instance = WorkflowInstanceState(**state_data)
            
            # æ›´æ–°å†å²
            current_history = instance.history[-1] if instance.history else None
            if current_history and not current_history.ended_at:
                current_history.ended_at = generate_timestamp()
                current_history.status = "completed"
                current_history.trigger_data_snapshot = trigger_data
            
            # è®°å½•æ–°é˜¶æ®µå¼€å§‹
            new_entry = HistoryEntry(
                phase=instance.current_phase,
                task="unknown",
                started_at=generate_timestamp(),
                trigger_data_snapshot=trigger_data
            )
            instance.history.append(new_entry)
            
            # åŠ è½½å·¥ä½œæµå®šä¹‰ä»¥ç¡®å®šä¸‹ä¸€é˜¶æ®µ
            # ï¼ˆç®€åŒ–ç‰ˆï¼šçº¿æ€§æ¨è¿›ï¼‰
            workflow_schema = {"phases": [{"name": "phase1"}, {"name": "phase2"}]}  # å®é™…åº”ä»å­˜å‚¨åŠ è½½
            phases = [p["name"] for p in workflow_schema.get("phases", [])]
            current_idx = phases.index(instance.current_phase) if instance.current_phase in phases else -1
            
            if current_idx >= 0 and current_idx + 1 < len(phases):
                instance.current_phase = phases[current_idx + 1]
                instance.status = "running"
            else:
                instance.status = "completed"
            
            instance.updated_at = generate_timestamp()
            if meta:
                instance.meta.update(meta)
            
            # ä¿å­˜æ–°çŠ¶æ€
            self.state_store.save_state(instance_id, asdict(instance))
            self._put_in_cache(instance_id, instance)
            
            return instance
    
    def get_workflow_instance_status(
        self,
        instance_id: str
    ) -> Optional[WorkflowInstanceState]:
        cached = self._get_from_cache(instance_id)
        if cached:
            return cached
        
        state_data = self.state_store.load_state(instance_id)
        if state_data:
            instance = WorkflowInstanceState(**state_data)
            self._put_in_cache(instance_id, instance)
            return instance
        return None
    
    def get_feature_status(
        self,
        feature_id: str,
        schema_name: str = "default"
    ) -> Dict:
        instance_ids = self.state_store.list_instances_by_feature(feature_id)
        instances = [
            self.get_workflow_instance_status(iid)
            for iid in instance_ids
        ]
        
        active_instances = [i for i in instances if i and i.status == "running"]
        completed_instances = [i for i in instances if i and i.status == "completed"]
        
        return {
            "feature_id": feature_id,
            "total_instances": len(instances),
            "running_count": len(active_instances),
            "completed_count": len(completed_instances),
            "latest_instance_id": instances[-1].instance_id if instances else None,
            "status": "completed" if completed_instances and not active_instances else "in_progress"
        }
```

---

## âœ… `chatflow/__init__.py`
```python
# chatflow/__init__.py
from .core.engine import WorkflowEngine

# å…¨å±€å¿«æ·è®¿é—®
engine = WorkflowEngine()

def init(storage_dir: str = ".chatflow") -> WorkflowEngine:
    """åˆå§‹åŒ–ChatFlowå¼•æ“"""
    global engine
    engine = WorkflowEngine(storage_dir=storage_dir)
    return engine

__all__ = ['WorkflowEngine', 'init', 'engine']
```

---

## ğŸš€ ChatFlow æä¾›ç»™ ChatCoder çš„æ ¸å¿ƒæ¥å£

### 1. åˆå§‹åŒ–
```python
import chatflow

# æ–¹å¼ä¸€ï¼šä½¿ç”¨é»˜è®¤é…ç½®
engine = chatflow.engine  # å…¨å±€å•ä¾‹

# æ–¹å¼äºŒï¼šè‡ªå®šä¹‰å­˜å‚¨è·¯å¾„
engine = chatflow.init("./my_project/.chatflow")
```

### 2. å¯åŠ¨å·¥ä½œæµ
```python
schema = {
    "name": "code_generation",
    "phases": [
        {"name": "requirement_analysis"},
        {"name": "design"},
        {"name": "implementation"}
    ]
}

initial_context = {
    "user_request": "åˆ›å»ºç”¨æˆ·æ³¨å†ŒåŠŸèƒ½"
}

instance_id = engine.start_workflow_instance(
    workflow_schema=schema,
    initial_context=initial_context,
    feature_id="feat_user_auth",
    meta={"user_id": "dev_alice", "session_id": "sess_123"}
)
```

### 3. æ¨è¿›å·¥ä½œæµ
```python
# æ‰§è¡Œå®Œä¸€ä¸ªé˜¶æ®µåè°ƒç”¨
result = engine.trigger_next_step(
    instance_id=instance_id,
    trigger_data={
        "analysis_result": "éœ€è¦é‚®ç®±éªŒè¯...",
        "code_diff": "+100 -20"
    },
    meta={"duration_sec": 45.2}
)
```

### 4. æŸ¥è¯¢çŠ¶æ€
```python
# è·å–å•ä¸ªå®ä¾‹çŠ¶æ€
status = engine.get_workflow_instance_status(instance_id)

# è·å–æ•´ä¸ªç‰¹æ€§çš„èšåˆçŠ¶æ€
feature_status = engine.get_feature_status("feat_user_auth")
```

---

## ğŸ“¦ å­˜å‚¨ç›®å½•ç¤ºä¾‹
```
.my_project/
â””â”€â”€ .chatflow/
    â”œâ”€â”€ instances/
    â”‚   â”œâ”€â”€ wfi_abc123.json
    â”‚   â””â”€â”€ wfi_abc123/
    â”‚       â””â”€â”€ tasks/
    â”‚           â”œâ”€â”€ requirement_analysis.json
    â”‚           â”œâ”€â”€ requirement_analysis.prompt.md
    â”‚           â””â”€â”€ requirement_analysis.ai_response.md
    â”œâ”€â”€ features/
    â”‚   â””â”€â”€ feat_user_auth.link  # å†…å®¹: "wfi_abc123"
    â””â”€â”€ .locks/
```

---

## âœ… v1.0 ç‰ˆæœ¬ç‰¹ç‚¹æ€»ç»“

| ç‰¹æ€§ | å®ç° |
|------|------|
| **å•ä¾‹å…±äº«** | è¿›ç¨‹å†…å…¨å±€å®ä¾‹ï¼Œå¤šæ¨¡å—å®‰å…¨è®¿é—® |
| **å†²çªé˜²æŠ¤** | æ–‡ä»¶é”é˜²æ­¢å¹¶å‘å†™å†²çª |
| **æ€§èƒ½ä¼˜åŒ–** | å†…å­˜ç¼“å­˜å‡å°‘ç£ç›˜I/O |
| **çŠ¶æ€å®Œæ•´** | æ”¯æŒå†å²è®°å½•ä¸å…ƒæ•°æ®é€ä¼  |
| **è½»é‡æ— ä¾èµ–** | ä»…ç”¨Pythonæ ‡å‡†åº“ |
| **å‘å‰å…¼å®¹** | ä¸ºv1.1+é¢„ç•™æ‰©å±•ç‚¹ |

æ­¤æ¡†æ¶å¯åœ¨ **<200è¡Œæ ¸å¿ƒä»£ç ** å†…å®Œæˆï¼Œå®Œç¾æ»¡è¶³æ‚¨â€œé¿å…è¿‡åº¦è®¾è®¡ã€æ”¯æŒå¤šæ¨¡å—ã€ä¸ªäººä½¿ç”¨â€çš„æ ¸å¿ƒéœ€æ±‚ï¼ŒåŒæ—¶ä¸ºæœªæ¥å‡çº§å¥ å®šåšå®åŸºç¡€ã€‚
