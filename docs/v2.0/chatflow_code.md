# ChatFlow v2.0 åŸºç¡€ä»£ç æ¡†æ¶

ä»¥ä¸‹æ˜¯åŸºäº v1.1 å‡çº§çš„ **v2.0 ç‰ˆæœ¬å®Œæ•´åŸºç¡€æ¡†æ¶**ã€‚åœ¨ä¿ç•™è½»é‡ã€æ— å¤–éƒ¨ä¾èµ–çš„å‰æä¸‹ï¼Œå®ç°äº†é€’å½’å·¥ä½œæµã€æ ‘çŠ¶çŠ¶æ€èšåˆå’Œèµ„æºé…é¢æ§åˆ¶ç­‰æ ¸å¿ƒèƒ½åŠ›ã€‚

---

## ğŸ“ é¡¹ç›®ç»“æ„
```bash
chatflow/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ engine.py          # æ ¸å¿ƒå¼•æ“ (é€’å½’å¢å¼º)
â”‚   â””â”€â”€ models.py          # æ•°æ®æ¨¡å‹ (æ ‘çŠ¶æ‹“æ‰‘)
â”‚   â””â”€â”€ schema.py          # Schema éªŒè¯ (å«é…é¢)
â”‚   â””â”€â”€ tree_status.py     # æ ‘çŠ¶çŠ¶æ€èšåˆ
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ file_state_store.py # æ–‡ä»¶å­˜å‚¨ (æ ‘çŠ¶ç´¢å¼•)
â”‚   â””â”€â”€ file_lock.py       # æ–‡ä»¶é”å·¥å…·
â””â”€â”€ utils/
    â”œâ”€â”€ id_generator.py
    â””â”€â”€ conditions.py      # æ¡ä»¶è¡¨è¾¾å¼æ±‚å€¼
```

---

## âœ… `chatflow/core/models.py` (æ ‘çŠ¶æ‹“æ‰‘æ¨¡å‹)
```python
# chatflow/core/models.py
from dataclasses import dataclass, field
from datetime import datetime
from typing import Dict, List, Optional, Any
from enum import Enum

class WorkflowStatus(Enum):
    CREATED = "created"
    RUNNING = "running"
    PAUSED = "paused"
    COMPLETED = "completed"
    FAILED = "failed"
    TERMINATED = "terminated"

@dataclass
class ResourceQuota:
    max_tokens: Optional[int] = None
    max_duration_sec: Optional[float] = None  # æœ€å¤§æ‰§è¡Œæ—¶é—´(ç§’)
    max_cost_usd: Optional[float] = None
    max_children: Optional[int] = None  # æœ€å¤§å­å·¥ä½œæµæ•°

@dataclass
class HistoryEntry:
    event_type: str
    phase: str
    task: str
    timestamp: float
     Dict[str, Any] = field(default_factory=dict)

@dataclass
class WorkflowState:
    """å†…å­˜ä¸­å®Œæ•´è¿è¡Œæ—¶çŠ¶æ€"""
    instance_id: str
    feature_id: str
    workflow_name: str
    current_phase: str
    variables: Dict[str, Any]
    status: WorkflowStatus
    
    # === v2.0 æ–°å¢ï¼šé€’å½’ä¸å±‚çº§ä¿¡æ¯ ===
    parent_instance_id: Optional[str] = None
    children: List[str] = field(default_factory=list)  # ç›´æ¥å­èŠ‚ç‚¹
    recursion_depth: int = 0
    resource_quota: ResourceQuota = field(default_factory=ResourceQuota)
    
    # === åŸºç¡€å­—æ®µ ===
    history: List[HistoryEntry] = field(default_factory=list)
    created_at: float = field(default_factory=lambda: datetime.now().timestamp())
    updated_at: float = field(default_factory=lambda: datetime.now().timestamp())
    meta: Dict[str, Any] = field(default_factory=dict)
    automation_level: int = 60

@dataclass
class WorkflowStatusInfo:
    """å¯¹å¤–æš´éœ²çš„ç²¾ç®€çŠ¶æ€"""
    instance_id: str
    status: str
    progress: float
    current_phase: str
    feature_id: str
    created_at: float
    updated_at: float
    depth: int = 0
    
    # === v2.0 æ–°å¢ï¼šæ ‘çŠ¶æ‘˜è¦ ===
    child_count: int = 0
    running_children: int = 0
    failed_children: int = 0
    completed_children: int = 0

@dataclass
class WorkflowTreeStatus:
    """æ•´æ£µå·¥ä½œæµæ ‘çš„çŠ¶æ€"""
    root_instance_id: str
    status: str  # aggregated status
    total_nodes: int
    completed_nodes: int
    failed_nodes: int
    running_nodes: int
    max_depth: int
    execution_time_sec: float
    total_cost_usd: float = 0.0
```

---

## âœ… `chatflow/core/schema.py` (å«é…é¢å®šä¹‰)
```python
# chatflow/core/schema.py
from dataclasses import dataclass
from typing import Dict, List, Optional
from .models import ResourceQuota, ConditionExpression

@dataclass
class PhaseDefinition:
    name: str
    task: str
    condition: Optional[ConditionExpression] = None
    fallback_phase: Optional[str] = None
    execution_strategy: str = "sequential"

@dataclass
class WorkflowSchema:
    name: str
    version: str
    phases: List[PhaseDefinition]
    
    # === v2.0 æ–°å¢ï¼šé»˜è®¤èµ„æºé…é¢ ===
    default_resource_quota: Optional[ResourceQuota] = None
    max_recursion_depth: Optional[int] = 5  # å…¨å±€æ·±åº¦é™åˆ¶
    
    def validate(self):
        names = [p.name for p in self.phases]
        if len(names) != len(set(names)):
            raise ValueError(f"Duplicate phase names in schema {self.name}@{self.version}")
        
        # æ£€æŸ¥æ·±åº¦é™åˆ¶åˆç†æ€§
        if self.max_recursion_depth is not None and self.max_recursion_depth < 1:
            raise ValueError("max_recursion_depth must be >= 1")
```

---

## âœ… `chatflow/core/tree_status.py` (æ ‘çŠ¶çŠ¶æ€èšåˆ)
```python
# chatflow/core/tree_status.py
from typing import Dict, List
from .models import WorkflowTreeStatus, WorkflowStatusInfo
from ..storage.file_state_store import FileStateStore

def aggregate_tree_status(
    root_instance_id: str,
    state_store: FileStateStore,
    current_timestamp: float
) -> WorkflowTreeStatus:
    """
    èšåˆä»¥ root_instance_id ä¸ºæ ¹çš„æ•´æ£µæ ‘çŠ¶æ€
    ä½¿ç”¨ .indexes/tree_index.json æå‡æ€§èƒ½
    """
    # è·å–æ‰€æœ‰åä»£å®ä¾‹ID
    descendant_ids = _get_all_descendants(root_instance_id, state_store)
    all_ids = [root_instance_id] + descendant_ids
    
    # åŠ è½½æ‰€æœ‰çŠ¶æ€ï¼ˆå¯ä¼˜åŒ–ä¸ºæ‰¹é‡åŠ è½½ï¼‰
    statuses = []
    for iid in all_ids:
        info = state_store.get_workflow_status_info(iid)
        if info:
            statuses.append(WorkflowStatusInfo(**info))
    
    if not statuses:
        raise ValueError(f"No instances found for tree {root_instance_id}")
    
    # è®¡ç®—èšåˆæŒ‡æ ‡
    status_map = {
        'completed': sum(1 for s in statuses if s.status == 'completed'),
        'failed': sum(1 for s in statuses if s.status == 'failed'),
        'running': sum(1 for s in statuses if s.status == 'running'),
        'other': sum(1 for s in statuses if s.status not in ['completed', 'failed', 'running'])
    }
    
    max_depth = max((s.depth for s in statuses), default=0)
    start_time = min((s.created_at for s in statuses), default=current_timestamp)
    execution_time = current_timestamp - start_time
    
    return WorkflowTreeStatus(
        root_instance_id=root_instance_id,
        status=_aggregate_status(status_map),
        total_nodes=len(statuses),
        completed_nodes=status_map['completed'],
        failed_nodes=status_map['failed'],
        running_nodes=status_map['running'],
        max_depth=max_depth,
        execution_time_sec=execution_time
    )

def _get_all_descendants(root_id: str, state_store: FileStateStore) -> List[str]:
    """ä»ç´¢å¼•æ–‡ä»¶è·å–æ‰€æœ‰åä»£"""
    index_file = state_store.indexes_dir / "tree_index.json"
    if index_file.exists():
        try:
            data = json.loads(index_file.read_text())
            return data.get(root_id, [])
        except:
            pass
    return []

def _aggregate_status(status_map: Dict[str, int]) -> str:
    """æ ¹æ®å­èŠ‚ç‚¹çŠ¶æ€è®¡ç®—èšåˆçŠ¶æ€"""
    if status_map['failed'] > 0:
        return 'failed'
    elif status_map['running'] > 0:
        return 'running'
    elif status_map['completed'] == status_map['completed'] + status_map['other']:
        return 'completed'
    else:
        return 'unknown'
```

---

## âœ… `chatflow/storage/file_state_store.py` (æ ‘çŠ¶ç´¢å¼•)
```python
# chatflow/storage/file_state_store.py
import json
from pathlib import Path
from typing import Dict, List, Optional
from .file_lock import FileLock
from ...utils.id_generator import generate_timestamp

class FileStateStore:
    def __init__(self, base_dir: str = ".chatflow"):
        self.base_dir = Path(base_dir).resolve()
        self.instances_dir = self.base_dir / "instances"
        self.features_dir = self.base_dir / "features"
        self.schemas_dir = self.base_dir / "schemas"
        self.locks_dir = self.base_dir / ".locks"
        self.indexes_dir = self.base_dir / ".indexes"
        
        for dir_path in [self.instances_dir, self.features_dir, self.schemas_dir, 
                        self.locks_dir, self.indexes_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
        
        # å†…å­˜ç´¢å¼•
        self._feature_index = self._load_index("feature_index.json")
        self._instance_index = self._load_index("instance_index.json")
        self._tree_index = self._load_index("tree_index.json")  # v2.0 æ–°å¢
    
    def _load_index(self, filename: str) -> Dict:
        index_file = self.indexes_dir / filename
        if index_file.exists():
            try:
                return json.loads(index_file.read_text())
            except:
                pass
        return {}
    
    def _persist_index(self):
        indexes = [
            ("feature_index.json", self._feature_index),
            ("instance_index.json", self._instance_index),
            ("tree_index.json", self._tree_index)  # v2.0 æ–°å¢
        ]
        for filename, data in indexes:
            (self.indexes_dir / filename).write_text(json.dumps(data, indent=2))
    
    def save_state(self, instance_id: str, state_ Dict):
        with FileLock(str(self.locks_dir / f"{instance_id}.lock")):
            # ... (åŒv1.1ä¿å­˜full_stateå’Œstatus_info)
            
            # === v2.0 æ–°å¢ï¼šæ›´æ–°æ ‘çŠ¶ç´¢å¼• ===
            parent_id = state_data.get("parent_instance_id")
            if parent_id:
                # å°†å½“å‰å®ä¾‹åŠ å…¥çˆ¶èŠ‚ç‚¹çš„childrenåˆ—è¡¨
                if parent_id not in self._instance_index:
                    # çˆ¶èŠ‚ç‚¹å¯èƒ½æœªåœ¨å†…å­˜ç´¢å¼•ä¸­
                    parent_file = self.instances_dir / f"{parent_id}.json"
                    if parent_file.exists():
                        try:
                            parent_data = json.loads(parent_file.read_text())
                            self._instance_index[parent_id] = parent_data
                        except: pass
                
                # æ›´æ–°çˆ¶å­å…³ç³»
                parent_children = self._instance_index.get(parent_id, {}).get("children", [])
                if instance_id not in parent_children:
                    parent_children.append(instance_id)
                    self._instance_index[parent_id]["children"] = parent_children
                
                # æ„å»ºæ ‘çŠ¶ç´¢å¼•ï¼šroot -> [all descendants]
                self._update_tree_index(parent_id, instance_id)
            
            self._persist_index()
    
    def _update_tree_index(self, parent_id: str, child_id: str):
        """æ›´æ–°æ ‘çŠ¶ç´¢å¼•ï¼Œå°†child_idåŠå…¶åä»£åŠ å…¥æ‰€æœ‰ç¥–å…ˆçš„ç´¢å¼•"""
        # æ‰¾åˆ°æ ¹èŠ‚ç‚¹
        root_id = parent_id
        while True:
            parent_info = self._instance_index.get(root_id, {})
            if not parent_info.get("parent_instance_id"):
                break
            root_id = parent_info["parent_instance_id"]
        
        # è·å–child_idçš„æ‰€æœ‰åä»£
        descendants = [child_id]
        if child_id in self._tree_index:
            descendants.extend(self._tree_index[child_id])
        
        # å°†descendantsåŠ å…¥æ ¹èŠ‚ç‚¹çš„æ ‘ç´¢å¼•
        if root_id not in self._tree_index:
            self._tree_index[root_id] = []
        for desc in descendants:
            if desc not in self._tree_index[root_id]:
                self._tree_index[root_id].append(desc)
        
        # é€’å½’æ›´æ–°æ‰€æœ‰ä¸­é—´èŠ‚ç‚¹
        current = parent_id
        while current != root_id:
            if current not in self._tree_index:
                self._tree_index[current] = []
            for desc in descendants:
                if desc not in self._tree_index[current]:
                    self._tree_index[current].append(desc)
            # ç§»åŠ¨åˆ°ä¸Šä¸€çº§
            current = self._instance_index.get(current, {}).get("parent_instance_id")
            if not current:
                break
```

---

## âœ… `chatflow/core/engine.py` (v2.0 é€’å½’å¼•æ“)
```python
# chatflow/core/engine.py
import threading
from typing import Dict, Optional, List, Any
from dataclasses import asdict
from pathlib import Path

from .models import *
from .schema import WorkflowSchema
from .tree_status import aggregate_tree_status
from ..storage.file_state_store import FileStateStore, IWorkflowStateStore
from ...utils.id_generator import generate_id, generate_timestamp
from ...utils.conditions import evaluate_condition

class IWorkflowEngine:
    # ... (v1.1 æ¥å£)
    def create_subworkflow(...) -> str: ...
    def get_workflow_tree_status(...) -> WorkflowTreeStatus: ...
    def monitor_workflow_tree(...) -> Dict: ...
    def terminate_workflow_tree(...): ...

class WorkflowEngine(IWorkflowEngine):
    _instance = None
    _lock = threading.RLock()
    
    def __init__(self, storage_dir: str = ".chatflow", state_store: IWorkflowStateStore = None):
        if not hasattr(self, 'initialized'):
            with self._lock:
                if not hasattr(self, 'initialized'):
                    self.state_store = state_store or FileStateStore(storage_dir)
                    self._state_cache = {}
                    self._schema_cache = {}
                    self.config = {
                        "max_recursion_depth": 5  # å…¨å±€é»˜è®¤
                    }
                    self.initialized = True
    
    # ==== v2.0 æ ¸å¿ƒï¼šåˆ›å»ºå­å·¥ä½œæµ ====
    def create_subworkflow(
        self,
        parent_instance_id: str,
        schema_id: str,
        context: Dict,
        resource_quota: Optional[ResourceQuota] = None,
        meta: Optional[Dict] = None
    ) -> str:
        with self._lock:
            # 1. åŠ è½½çˆ¶å®ä¾‹çŠ¶æ€
            parent_state = self.get_workflow_state(parent_instance_id)
            if not parent_state:
                raise ValueError(f"Parent instance {parent_instance_id} not found")
            
            # 2. å®‰å…¨æ£€æŸ¥ï¼šé€’å½’æ·±åº¦
            new_depth = parent_state.recursion_depth + 1
            global_limit = self.config["max_recursion_depth"]
            schema = self._load_schema_from_file(schema_id)
            schema_limit = schema.max_recursion_depth
            
            effective_limit = min(
                d for d in [global_limit, schema_limit] if d is not None
            ) if any(d is not None for d in [global_limit, schema_limit]) else 5
            
            if new_depth > effective_limit:
                raise MaxRecursionDepthExceededError(
                    current=new_depth, 
                    max=effective_limit,
                    instance_id=parent_instance_id
                )
            
            # 3. ç»§æ‰¿ä¸åˆå¹¶é…ç½®
            inherited_meta = {**parent_state.meta}
            if meta:
                inherited_meta.update(meta)
            
            final_quota = resource_quota or parent_state.resource_quota
            if not final_quota.max_children:
                final_quota.max_children = parent_state.resource_quota.max_children
            
            # 4. åˆ›å»ºå­å®ä¾‹
            sub_id = f"wfi_{generate_id()}"
            schema = self._load_schema_from_file(schema_id)
            initial_phase = schema.phases[0].name if schema.phases else "unknown"
            
            child_state = WorkflowState(
                instance_id=sub_id,
                feature_id=parent_state.feature_id,
                workflow_name=schema.name,
                current_phase=initial_phase,
                variables=context.copy(),
                status=WorkflowStatus.CREATED,
                parent_instance_id=parent_instance_id,
                recursion_depth=new_depth,
                resource_quota=final_quota,
                meta=inherited_meta
            )
            
            # 5. å»ºç«‹çˆ¶å­å…³ç³»
            parent_state.children.append(sub_id)
            self.state_store.save_state(parent_instance_id, asdict(parent_state))
            self._clear_cache(parent_instance_id)
            
            # 6. ä¿å­˜å­å®ä¾‹
            self.state_store.save_state(sub_id, asdict(child_state))
            self._cache_state(sub_id, child_state)
            
            # 7. è®°å½•äº‹ä»¶
            parent_state.history.append(HistoryEntry(
                event_type="subworkflow_created",
                phase="system",
                task="orchestration",
                timestamp=generate_timestamp(),
                data={"child_id": sub_id, "schema": schema_id}
            ))
            
            return sub_id
    
    # ==== v2.0 æ ¸å¿ƒï¼šè·å–æ ‘çŠ¶çŠ¶æ€ ====
    def get_workflow_tree_status(self, root_instance_id: str) -> WorkflowTreeStatus:
        current_ts = generate_timestamp()
        return aggregate_tree_status(root_instance_id, self.state_store, current_ts)
    
    # ==== v2.0 æ ¸å¿ƒï¼šç›‘æ§æ ‘çŠ¶æ‰§è¡Œ ====
    def monitor_workflow_tree(self, root_instance_id: str) -> Dict:
        """è¿”å›å¯ç”¨äºUIæ¸²æŸ“çš„æ ‘çŠ¶ç»“æ„æ•°æ®"""
        tree_status = self.get_workflow_tree_status(root_instance_id)
        
        # è·å–æ ¹èŠ‚ç‚¹çŠ¶æ€
        root_info = self.get_workflow_status_info(root_instance_id)
        
        # è·å–ç›´æ¥å­èŠ‚ç‚¹çŠ¶æ€
        children_statuses = []
        if root_info and hasattr(root_info, 'children'):
            for child_id in getattr(root_info, 'children', []):
                child_info = self.get_workflow_status_info(child_id)
                if child_info:
                    children_statuses.append(child_info)
        
        return {
            "root": root_info,
            "tree_status": asdict(tree_status),
            "children": [asdict(c) for c in children_statuses],
            "timestamp": generate_timestamp()
        }
    
    # ==== v2.0 æ ¸å¿ƒï¼šç»ˆæ­¢æ•´ä¸ªå·¥ä½œæµæ ‘ ====
    def terminate_workflow_tree(self, root_instance_id: str, reason: str):
        with self._lock:
            # 1. è·å–æ‰€æœ‰åä»£
            descendant_ids = self.state_store._tree_index.get(root_instance_id, [])
            all_ids = [root_instance_id] + descendant_ids
            
            # 2. ç»ˆæ­¢æ¯ä¸ªå®ä¾‹
            for instance_id in all_ids:
                state_data = self.state_store.load_state(instance_id)
                if state_data and state_data.get("status") not in ["completed", "failed", "terminated"]:
                    state_data["status"] = "terminated"
                    state_data["updated_at"] = generate_timestamp()
                    
                    # è®°å½•ç»ˆæ­¢äº‹ä»¶
                    history = state_data.get("history", [])
                    history.append({
                        "event_type": "workflow_terminated",
                        "phase": "system",
                        "task": "orchestration",
                        "timestamp": generate_timestamp(),
                        "data": {"reason": reason}
                    })
                    state_data["history"] = history
                    
                    self.state_store.save_state(instance_id, state_data)
                    self._clear_cache(instance_id)
    
    # ==== åŸæœ‰æ–¹æ³• (ç•¥ä½œè°ƒæ•´) ====
    def trigger_next_step(...):
        # ... (åŒv1.1)
        # åœ¨æ¨è¿›æ—¶æ£€æŸ¥èµ„æºé…é¢
        if state.resource_quota.max_duration_sec:
            elapsed = generate_timestamp() - state.created_at
            if elapsed > state.resource_quota.max_duration_sec:
                state.status = WorkflowStatus.FAILED
                # ... è®°å½•å¤±è´¥
        # ...
```

---

## ğŸš€ ChatFlow v2.0 å¯¹å¤–æä¾›çš„æ ¸å¿ƒæ¥å£

### 1. åˆå§‹åŒ–
```python
import chatflow
engine = chatflow.engine  # æˆ– chatflow.init("./path")
```

### 2. å¯åŠ¨ä¸»å·¥ä½œæµ
```python
main_result = engine.start_workflow_instance(
    workflow_schema={
        "name": "major-refactor",
        "version": "1.0",
        "max_recursion_depth": 4,
        "default_resource_quota": {
            "max_tokens": 100000,
            "max_duration_sec": 7200  # 2å°æ—¶
        },
        "phases": [...]
    },
    initial_context={...},
    feature_id="feat_refactor_v2"
)
```

### 3. åˆ›å»ºå­å·¥ä½œæµï¼ˆä»»åŠ¡åˆ†è§£ï¼‰
```python
# ä¸»å·¥ä½œæµæ‰§è¡Œåˆ°æŸé˜¶æ®µæ—¶
sub_id = engine.create_subworkflow(
    parent_instance_id=main_result.instance_id,
    schema_id="database-migration",
    context={
        "table": "users", 
        "migration_plan": "..."
    },
    resource_quota=ResourceQuota(
        max_tokens=20000,
        max_duration_sec=1800  # 30åˆ†é’Ÿ
    ),
    meta={"priority": "high"}
)
```

### 4. ç›‘æ§å·¥ä½œæµæ ‘
```python
# å®æ—¶è·å–æ ‘çŠ¶æ‰§è¡ŒçŠ¶æ€
tree_monitor = engine.monitor_workflow_tree(main_result.instance_id)

print(f"æ•´ä½“çŠ¶æ€: {tree_monitor['tree_status']['status']}")
print(f"è€—æ—¶: {tree_monitor['tree_status']['execution_time_sec']:.1f}s")
for child in tree_monitor['children']:
    print(f"  å­ä»»åŠ¡ {child['instance_id']}: {child['status']} ({child['current_phase']})")
```

### 5. è·å–æ ‘çŠ¶èšåˆçŠ¶æ€
```python
tree_status = engine.get_workflow_tree_status(main_result.instance_id)
if tree_status.failed_nodes > 0:
    print("æœ‰å­ä»»åŠ¡å¤±è´¥ï¼Œéœ€äººå·¥ä»‹å…¥")
elif tree_status.running_nodes == 0:
    print("æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
```

### 6. ç´§æ€¥ç»ˆæ­¢
```python
# å‘ç°ä¸¥é‡é—®é¢˜æ—¶ç»ˆæ­¢æ•´ä¸ªä»»åŠ¡æ ‘
engine.terminate_workflow_tree(
    main_result.instance_id,
    reason="Critical error detected in subtask"
)
```

### 7. æŸ¥è¯¢å•ä¸ªå®ä¾‹çŠ¶æ€
```python
# ä¸v1.1å…¼å®¹
state = engine.get_workflow_state(sub_id)
status_info = engine.get_workflow_status_info(sub_id)
```

---

## ğŸ“¦ å­˜å‚¨ç›®å½•ç¤ºä¾‹
```
.my_project/
â””â”€â”€ .chatflow/
    â”œâ”€â”€ instances/
    â”‚   â”œâ”€â”€ wfi_main.json               # ä¸»å®ä¾‹çŠ¶æ€
    â”‚   â””â”€â”€ wfi_main/
    â”‚       â”œâ”€â”€ full_state.json
    â”‚       â”œâ”€â”€ history.ndjson
    â”‚       â”œâ”€â”€ children/               # å­å®ä¾‹é“¾æ¥
    â”‚       â”‚   â””â”€â”€ wfi_db_migrate.link # å†…å®¹: "wfi_step1,wfi_step2"
    â”‚       â””â”€â”€ tasks/
    â”‚
    â”‚   â”œâ”€â”€ wfi_db_migrate.json         # å­å®ä¾‹çŠ¶æ€
    â”‚   â””â”€â”€ wfi_db_migrate/
    â”‚       â”œâ”€â”€ parent_link.txt         # å†…å®¹: "wfi_main"
    â”‚       â”œâ”€â”€ full_state.json
    â”‚       â””â”€â”€ ...
    â”œâ”€â”€ .indexes/
    â”‚   â”œâ”€â”€ feature_index.json
    â”‚   â”œâ”€â”€ instance_index.json  
    â”‚   â””â”€â”€ tree_index.json             # {wfi_main: [wfi_db_mig, wfi_api_upd, ...]}
    â””â”€â”€ schemas/
        â””â”€â”€ major-refactor.yaml
```

---

## âœ… v2.0 å…³é”®ä¼˜åŠ¿æ€»ç»“

| ç‰¹æ€§ | ç”¨æˆ·ä»·å€¼ |
|------|----------|
| **é€’å½’å·¥ä½œæµ** | AI å¯è‡ªä¸»åˆ†è§£å¤æ‚ä»»åŠ¡ |
| **æ ‘çŠ¶ç›‘æ§** | å…¨å±€æŒæ§ä»»åŠ¡æ‰§è¡Œå…¨æ™¯ |
| **æ·±åº¦é™åˆ¶** | é˜²æ­¢æ— é™é€’å½’ï¼Œä¿éšœå®‰å…¨ |
| **èµ„æºé…é¢** | æ§åˆ¶æˆæœ¬ä¸æ‰§è¡Œæ—¶é—´ |
| **ç´§æ€¥ç»ˆæ­¢** | é£é™©å¯æ§ï¼Œéšæ—¶å¹²é¢„ |
| **å‘åå…¼å®¹** | æ—§æ¥å£ä»å¯ç”¨ |

æ­¤æ¡†æ¶è®© ChatFlow çœŸæ­£å…·å¤‡äº†å¤„ç†â€œæ¨¡ç³Šã€å¤æ‚â€å¼€å‘ä»»åŠ¡çš„èƒ½åŠ›ï¼Œå®ç°äº†ä»â€œæ‰§è¡Œè€…â€åˆ°â€œåä½œè€…â€çš„è·ƒè¿ã€‚
