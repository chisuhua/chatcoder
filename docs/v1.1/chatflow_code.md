# ChatFlow v1.1 åŸºç¡€ä»£ç æ¡†æ¶

ä»¥ä¸‹æ˜¯åŸºäº v1.0 å‡çº§çš„ **v1.1 ç‰ˆæœ¬å®Œæ•´åŸºç¡€æ¡†æ¶**ã€‚åœ¨ä¿æŒè½»é‡ã€æ— å¤–éƒ¨ä¾èµ–çš„å‰æä¸‹ï¼Œå®ç°äº† Schema éªŒè¯ã€ä¸‰é‡çŠ¶æ€ä½“ç³»ã€æ¡ä»¶åˆ†æ”¯å’Œ Dry Run ç­‰æ ¸å¿ƒèƒ½åŠ›ã€‚

---

## ğŸ“ é¡¹ç›®ç»“æ„
```bash
chatflow/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ engine.py          # æ ¸å¿ƒå¼•æ“ (å¢å¼º)
â”‚   â””â”€â”€ models.py          # æ•°æ®æ¨¡å‹ (ä¸‰é‡çŠ¶æ€)
â”‚   â””â”€â”€ schema.py          # Schema éªŒè¯
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ file_state_store.py # æ–‡ä»¶å­˜å‚¨ (å¢å¼º)
â”‚   â””â”€â”€ file_lock.py       # æ–‡ä»¶é”å·¥å…·
â””â”€â”€ utils/
    â”œâ”€â”€ id_generator.py
    â””â”€â”€ conditions.py      # æ¡ä»¶è¡¨è¾¾å¼æ±‚å€¼
```

---

## âœ… `chatflow/core/models.py` (ä¸‰é‡çŠ¶æ€ä½“ç³»)
```python
# chatflow/core/models.py
from dataclasses import dataclass, field
from datetime import datetime
from typing import Dict, List, Optional, Any
from enum import Enum

class WorkflowStatus(Enum):
    CREATED = "created"
    RUNNING = "running"
    PAUSED = "paused"
    COMPLETED = "completed"
    FAILED = "failed"

class TaskStatus(Enum):
    PENDING = "pending"
    RUNNING = "running"
    SUCCESS = "success"
    FAILED = "failed"
    SKIPPED = "skipped"

@dataclass
class HistoryEntry:
    event_type: str  # workflow_started, phase_started, phase_completed, etc.
    phase: str
    task: str
    timestamp: float
    data: Dict[str, Any] = field(default_factory=dict)  # trigger_data_snapshot, metricsç­‰

@dataclass
class TaskExecutionRecord:
    phase_name: str
    status: str
    started_at: float
    ended_at: Optional[float] = None
    prompt_checksum: str = ""
    response_checksum: str = ""
    artifact_paths: Dict[str, str] = field(default_factory=dict)

@dataclass
class WorkflowState:
    """å†…å­˜ä¸­å®Œæ•´è¿è¡Œæ—¶çŠ¶æ€"""
    instance_id: str
    feature_id: str
    workflow_name: str
    current_phase: str
    variables: Dict[str, Any]
    status: WorkflowStatus
    history: List[HistoryEntry] = field(default_factory=list)
    created_at: float = field(default_factory=lambda: datetime.now().timestamp())
    updated_at: float = field(default_factory=lambda: datetime.now().timestamp())
    meta: Dict[str, Any] = field(default_factory=dict)
    automation_level: int = 60  # 0-100

@dataclass
class WorkflowStatusInfo:
    """å¯¹å¤–æš´éœ²çš„ç²¾ç®€çŠ¶æ€"""
    instance_id: str
    status: str  # "running", "completed"
    progress: float  # 0.0 - 1.0
    current_phase: str
    feature_id: str
    created_at: float
    updated_at: float
    depth: int = 0  # é€’å½’æ·±åº¦ (v2é¢„ç•™)

# è¿”å›å€¼å¯¹è±¡
@dataclass
class WorkflowStartResult:
    instance_id: str
    initial_phase: str
    created_at: float
```

---

## âœ… `chatflow/core/schema.py` (Schema éªŒè¯)
```python
# chatflow/core/schema.py
from dataclasses import dataclass
from typing import Dict, List, Optional
from .models import TaskStatus

@dataclass
class ConditionExpression:
    operator: str  # "and", "or", "not"
    operands: List['ConditionTerm']

@dataclass
class ConditionTerm:
    field: str
    operator: str  # "=", "!=", ">", "<", ">=", "<="
    value: Any

@dataclass
class PhaseDefinition:
    name: str
    task: str
    condition: Optional[ConditionExpression] = None
    fallback_phase: Optional[str] = None  # æ¡ä»¶ä¸æ»¡è¶³æ—¶è·³è½¬
    execution_strategy: str = "sequential"  # sequential, parallel, concurrent

@dataclass
class WorkflowSchema:
    name: str
    version: str
    phases: List[PhaseDefinition]
    
    def validate(self):
        # æ£€æŸ¥phaseåç§°å”¯ä¸€æ€§
        names = [p.name for p in self.phases]
        if len(names) != len(set(names)):
            raise ValueError(f"Duplicate phase names in schema {self.name}@{self.version}")
        
        # å¯æ·»åŠ æ›´å¤šé™æ€æ£€æŸ¥...
```

---

## âœ… `chatflow/utils/conditions.py` (æ¡ä»¶æ±‚å€¼)
```python
# chatflow/utils/conditions.py
from typing import Dict, Any
from ..core.schema import ConditionExpression, ConditionTerm

def evaluate_condition(condition: ConditionExpression, context: Dict[str, Any]) -> bool:
    """é€’å½’æ±‚å€¼æ¡ä»¶è¡¨è¾¾å¼"""
    if condition.operator == "and":
        return all(_evaluate_term(term, context) for term in condition.operands)
    elif condition.operator == "or":
        return any(_evaluate_term(term, context) for term in condition.operands)
    elif condition.operator == "not":
        return not _evaluate_term(condition.operands[0], context)
    else:
        raise ValueError(f"Unknown operator: {condition.operator}")

def _evaluate_term(term: 'ConditionTerm', context: Dict[str, Any]) -> bool:
    """æ±‚å€¼å•ä¸ªæ¡ä»¶é¡¹"""
    value = _get_nested_value(term.field, context)
    
    if term.operator == "=":
        return value == term.value
    elif term.operator == "!=":
        return value != term.value
    elif term.operator == ">":
        return value > term.value
    elif term.operator == "<":
        return value < term.value
    elif term.operator == ">=":
        return value >= term.value
    elif term.operator == "<=":
        return value <= term.value
    else:
        raise ValueError(f"Unknown operator: {term.operator}")

def _get_nested_value(path: str, obj: Dict[str, Any]) -> Any:
    """æ”¯æŒç‚¹å·åµŒå¥—è®¿é—®: "code.risk_level" """
    keys = path.split('.')
    for key in keys:
        if isinstance(obj, dict) and key in obj:
            obj = obj[key]
        else:
            return None
    return obj
```

---

## âœ… `chatflow/storage/file_state_store.py` (å¢å¼ºç‰ˆ)
```python
# chatflow/storage/file_state_store.py
import json
import hashlib
from pathlib import Path
from typing import Dict, List, Optional
from .file_lock import FileLock
from ...utils.id_generator import generate_timestamp

class IWorkflowStateStore:
    def save_state(self, instance_id: str, state_ Dict): ...
    def load_state(self, instance_id: str) -> Optional[Dict]: ...
    def list_instances_by_feature(self, feature_id: str) -> List[str]: ...
    def save_task_artifacts(...): ...

class FileStateStore(IWorkflowStateStore):
    def __init__(self, base_dir: str = ".chatflow"):
        self.base_dir = Path(base_dir).resolve()
        self.instances_dir = self.base_dir / "instances"
        self.features_dir = self.base_dir / "features"
        self.schemas_dir = self.base_dir / "schemas"
        self.locks_dir = self.base_dir / ".locks"
        self.indexes_dir = self.base_dir / ".indexes"
        
        for dir_path in [self.instances_dir, self.features_dir, self.schemas_dir, 
                        self.locks_dir, self.indexes_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
        
        # å†…å­˜ç´¢å¼•ï¼ˆå¯é€‰æŒä¹…åŒ–ï¼‰
        self._feature_index = self._load_index("feature_index.json")
        self._instance_index = self._load_index("instance_index.json")
    
    def _load_index(self, filename: str) -> Dict:
        index_file = self.indexes_dir / filename
        if index_file.exists():
            try:
                return json.loads(index_file.read_text())
            except:
                pass
        return {}
    
    def _persist_index(self):
        # å¼‚æ­¥æˆ–å®šæœŸä¿å­˜
        (self.indexes_dir / "feature_index.json").write_text(
            json.dumps(self._feature_index, indent=2)
        )
        (self.indexes_dir / "instance_index.json").write_text(
            json.dumps(self._instance_index, indent=2)
        )
    
    def save_state(self, instance_id: str, state_ Dict):
        with FileLock(str(self.locks_dir / f"{instance_id}.lock")):
            # 1. ä¿å­˜å®Œæ•´çŠ¶æ€åˆ°å­ç›®å½•
            instance_subdir = self.instances_dir / instance_id
            instance_subdir.mkdir(exist_ok=True)
            
            full_state_file = instance_subdir / "full_state.json"
            temp_file = full_state_file.with_suffix(".json.tmp")
            temp_file.write_text(json.dumps(state_data, indent=2), encoding="utf-8")
            temp_file.rename(full_state_file)
            
            # 2. ä¿å­˜ç²¾ç®€çŠ¶æ€åˆ°ä¸»ç›®å½•ï¼ˆç”¨äºå¿«é€ŸæŸ¥è¯¢ï¼‰
            status_info = {
                "instance_id": state_data["instance_id"],
                "status": state_data["status"],
                "current_phase": state_data["current_phase"],
                "feature_id": state_data["feature_id"],
                "created_at": state_data["created_at"],
                "updated_at": state_data["updated_at"],
                "progress": self._calculate_progress(state_data),
                "depth": state_data.get("recursion_depth", 0)
            }
            main_file = self.instances_dir / f"{instance_id}.json"
            main_temp = main_file.with_suffix(".json.tmp")
            main_temp.write_text(json.dumps(status_info, indent=2), encoding="utf-8")
            main_temp.rename(main_file)
            
            # 3. è¿½åŠ å†å²äº‹ä»¶
            if state_data.get("new_events"):
                history_file = instance_subdir / "history.ndjson"
                with open(history_file, "a", encoding="utf-8") as f:
                    for event in state_data["new_events"]:
                        f.write(json.dumps(event) + "\n")
                state_data.pop("new_events", None)
            
            # 4. æ›´æ–°ç´¢å¼•
            feature_id = state_data["feature_id"]
            self._feature_index.setdefault(feature_id, []).append(instance_id)
            self._instance_index[instance_id] = {
                "feature_id": feature_id,
                "status": state_data["status"],
                "updated_at": state_data["updated_at"]
            }
            self._persist_index()  # å¯ä¼˜åŒ–ä¸ºå¼‚æ­¥
    
    def _calculate_progress(self, state_ Dict) -> float:
        # ç®€å•å®ç°ï¼šå·²å®Œæˆé˜¶æ®µæ•° / æ€»é˜¶æ®µæ•°
        # å®é™…åº”ä»schemaè·å–æ€»é˜¶æ®µ
        total_phases = 5  # ç¤ºä¾‹
        completed = len([h for h in state_data.get("history", []) 
                        if h["event_type"] == "phase_completed"])
        return min(completed / total_phases, 1.0) if total_phases > 0 else 0.0
    
    def load_state(self, instance_id: str) -> Optional[Dict]:
        full_state_file = self.instances_dir / instance_id / "full_state.json"
        with FileLock(str(self.locks_dir / f"{instance_id}.lock")):
            if full_state_file.exists():
                try:
                    content = full_state_file.read_text(encoding="utf-8")
                    return json.loads(content)
                except (IOError, json.JSONDecodeError) as e:
                    print(f"Error loading state for {instance_id}: {e}")
        return None
    
    def get_workflow_status_info(self, instance_id: str) -> Optional[Dict]:
        """è·å–ç²¾ç®€çŠ¶æ€ï¼ˆæ¨èç”¨äºUIï¼‰"""
        status_file = self.instances_dir / f"{instance_id}.json"
        if status_file.exists():
            try:
                content = status_file.read_text(encoding="utf-8")
                return json.loads(content)
            except:
                pass
        return None
    
    def get_workflow_history(self, instance_id: str) -> List[Dict]:
        """è·å–å®Œæ•´å†å²äº‹ä»¶æµ"""
        history_file = self.instances_dir / instance_id / "history.ndjson"
        events = []
        if history_file.exists():
            try:
                for line in history_file.open(encoding="utf-8"):
                    if line.strip():
                        events.append(json.loads(line))
            except:
                pass
        return events
```

---

## âœ… `chatflow/core/engine.py` (v1.1 å¢å¼ºç‰ˆ)
```python
# chatflow/core/engine.py
import threading
from typing import Dict, Optional, List, Any
from dataclasses import asdict
from pathlib import Path

from .models import *
from .schema import WorkflowSchema
from ..storage.file_state_store import FileStateStore, IWorkflowStateStore
from ...utils.id_generator import generate_id, generate_timestamp
from ...utils.conditions import evaluate_condition

class IWorkflowEngine:
    def start_workflow_instance(...) -> WorkflowStartResult: ...
    def trigger_next_step(...) -> WorkflowInstanceState: ...
    def get_workflow_state(...) -> Optional[WorkflowState]: ...
    def get_workflow_status_info(...) -> Optional[WorkflowStatusInfo]: ...
    def get_workflow_history(...) -> List[HistoryEntry]:
        raise NotImplementedError

class WorkflowEngine(IWorkflowEngine):
    _instance = None
    _lock = threading.RLock()
    
    def __init__(self, storage_dir: str = ".chatflow", state_store: IWorkflowStateStore = None):
        if not hasattr(self, 'initialized'):
            with self._lock:
                if not hasattr(self, 'initialized'):
                    self.state_store = state_store or FileStateStore(storage_dir)
                    self._state_cache = {}  # instance_id -> (state, timestamp)
                    self._schema_cache = {}  # schema_key -> WorkflowSchema
                    self.initialized = True
    
    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    # ==== Schema Management ====
    def _load_schema_from_file(self, schema_name: str, version: str = "latest") -> WorkflowSchema:
        schema_key = f"{schema_name}@{version}"
        if schema_key in self._schema_cache:
            return self._schema_cache[schema_key]
        
        schema_path = Path(self.state_store.schemas_dir) / f"{schema_name}.yaml"
        if not schema_path.exists():
            schema_path = Path(self.state_store.schemas_dir) / f"{schema_name}.json"
        
        if not schema_path.exists():
            raise FileNotFoundError(f"Schema {schema_name} not found")
        
        import yaml  # å»ºè®®ä½œä¸ºå¯é€‰ä¾èµ–
        with open(schema_path, 'r') as f:
            data = yaml.safe_load(f)
        
        schema = WorkflowSchema(**data)
        schema.validate()
        self._schema_cache[schema_key] = schema
        return schema
    
    # ==== State Caching ====
    def _get_cached_state(self, instance_id: str) -> Optional[WorkflowState]:
        if instance_id in self._state_cache:
            state, ts = self._state_cache[instance_id]
            if generate_timestamp() - ts < 30:
                return state
            else:
                del self._state_cache[instance_id]
        return None
    
    def _cache_state(self, instance_id: str, state: WorkflowState):
        self._state_cache[instance_id] = (state, generate_timestamp())
    
    def _clear_cache(self, instance_id: str):
        self._state_cache.pop(instance_id, None)
    
    # ==== Main API ====
    def start_workflow_instance(
        self,
        workflow_schema: Dict,
        initial_context: Dict,
        feature_id: str,
        meta: Optional[Dict] = None
    ) -> WorkflowStartResult:
        with self._lock:
            # ä»å­—å…¸åˆ›å»ºå¹¶éªŒè¯Schema
            schema = WorkflowSchema(**workflow_schema)
            schema.validate()
            
            instance_id = f"wfi_{generate_id()}"
            initial_phase = schema.phases[0].name if schema.phases else "unknown"
            
            state = WorkflowState(
                instance_id=instance_id,
                feature_id=feature_id,
                workflow_name=schema.name,
                current_phase=initial_phase,
                variables=initial_context.copy(),
                status=WorkflowStatus.CREATED,
                meta=meta or {},
                automation_level=meta.get("automation_level", 60) if meta else 60
            )
            
            # è®°å½•å¯åŠ¨äº‹ä»¶
            state.history.append(HistoryEntry(
                event_type="workflow_started",
                phase=initial_phase,
                task="system",
                timestamp=generate_timestamp()
            ))
            
            self.state_store.save_state(instance_id, asdict(state))
            self._cache_state(instance_id, state)
            
            return WorkflowStartResult(
                instance_id=instance_id,
                initial_phase=initial_phase,
                created_at=state.created_at
            )
    
    def trigger_next_step(
        self,
        instance_id: str,
        trigger_ Optional[Dict] = None,
        dry_run: bool = False,
        meta: Optional[Dict] = None
    ) -> WorkflowState:
        with self._lock:
            # åŠ è½½å½“å‰çŠ¶æ€
            state = self._get_cached_state(instance_id)
            if not state:
                state_data = self.state_store.load_state(instance_id)
                if not state_
                    raise ValueError(f"Instance {instance_id} not found")
                state = WorkflowState(**state_data)
            
            # åŠ è½½å·¥ä½œæµå®šä¹‰
            schema = self._load_schema_from_file(state.workflow_name)
            
            # è®°å½•å½“å‰é˜¶æ®µå®Œæˆ
            if state.history and state.history[-1].phase == state.current_phase:
                state.history[-1].data["ended_at"] = generate_timestamp()
                state.history[-1].data["status"] = "completed"
                if trigger_
                    state.history[-1].data["trigger_data_snapshot"] = trigger_data
            
            # æ›´æ–°å˜é‡
            if trigger_
                state.variables.update(trigger_data)
            
            # è·å–ä¸‹ä¸€é˜¶æ®µå€™é€‰
            current_idx = next((i for i, p in enumerate(schema.phases) 
                              if p.name == state.current_phase), -1)
            
            if current_idx == -1 or current_idx >= len(schema.phases) - 1:
                # å·²åˆ°æœ€åï¼Œæ ‡è®°å®Œæˆ
                state.status = WorkflowStatus.COMPLETED
                new_phase = None
            else:
                # è·å–ä¸‹ä¸€é˜¶æ®µå®šä¹‰
                next_phase_def = schema.phases[current_idx + 1]
                
                # æ£€æŸ¥æ¡ä»¶
                if next_phase_def.condition:
                    if not evaluate_condition(next_phase_def.condition, state.variables):
                        # æ¡ä»¶ä¸æ»¡è¶³ï¼Œèµ°fallbackæˆ–è·³è¿‡
                        if next_phase_def.fallback_phase:
                            new_phase = next_phase_def.fallback_phase
                        else:
                            # è·³è¿‡æ­¤é˜¶æ®µï¼Œç»§ç»­ä¸‹ä¸€ä¸‹
                            new_phase = schema.phases[current_idx + 2].name if current_idx + 2 < len(schema.phases) else None
                    else:
                        new_phase = next_phase_def.name
                else:
                    new_phase = next_phase_def.name
                
                if new_phase:
                    state.current_phase = new_phase
                    state.status = WorkflowStatus.RUNNING
            
            # è®°å½•æ–°é˜¶æ®µå¼€å§‹
            if new_phase:
                state.history.append(HistoryEntry(
                    event_type="phase_started",
                    phase=new_phase,
                    task=schema.phases[current_idx + 1].task,
                    timestamp=generate_timestamp(),
                    data={"trigger_data_snapshot": trigger_data}
                ))
            
            # æ›´æ–°æ—¶é—´æˆ³
            state.updated_at = generate_timestamp()
            if meta:
                state.meta.update(meta)
            
            # Dry Run æ¨¡å¼ï¼šä¸ä¿å­˜
            if not dry_run:
                # å‡†å¤‡ä¿å­˜æ•°æ®ï¼ˆåŒ…å«æ–°äº‹ä»¶ï¼‰
                save_data = asdict(state)
                save_data["new_events"] = [
                    asdict(e) for e in state.history[-2:]  # æœ€è¿‘ä¸¤ä¸ªäº‹ä»¶
                ] if len(state.history) >= 2 else []
                
                self.state_store.save_state(instance_id, save_data)
                if not dry_run:
                    self._cache_state(instance_id, state)
            else:
                # Dry Runï¼šæ¸…é™¤ç¼“å­˜ï¼Œå¼ºåˆ¶ä¸‹æ¬¡é‡æ–°åŠ è½½
                self._clear_cache(instance_id)
            
            return state
    
    def get_workflow_state(self, instance_id: str) -> Optional[WorkflowState]:
        cached = self._get_cached_state(instance_id)
        if cached:
            return cached
        
        state_data = self.state_store.load_state(instance_id)
        if state_
            state = WorkflowState(**state_data)
            self._cache_state(instance_id, state)
            return state
        return None
    
    def get_workflow_status_info(self, instance_id: str) -> Optional[WorkflowStatusInfo]:
        return self.state_store.get_workflow_status_info(instance_id)
    
    def get_workflow_history(self, instance_id: str) -> List[HistoryEntry]:
        raw_events = self.state_store.get_workflow_history(instance_id)
        return [HistoryEntry(**e) for e in raw_events]
```

---

## ğŸš€ ChatFlow v1.1 å¯¹å¤–æä¾›çš„æ ¸å¿ƒæ¥å£

### 1. åˆå§‹åŒ–
```python
import chatflow

# ä½¿ç”¨é»˜è®¤è·¯å¾„
engine = chatflow.engine

# è‡ªå®šä¹‰è·¯å¾„
engine = chatflow.init("./my_project/.chatflow")
```

### 2. å¯åŠ¨å·¥ä½œæµï¼ˆè¿”å›ç»“æ„åŒ–ç»“æœï¼‰
```python
result = engine.start_workflow_instance(
    workflow_schema={
        "name": "code_review",
        "version": "1.1",
        "phases": [
            {"name": "static_analysis", "task": "tool"},
            {"name": "ai_review", "task": "ai", "condition": {...}}
        ]
    },
    initial_context={"pr_url": "https://..."},
    feature_id="feat_pr_123",
    meta={"user_id": "alice", "automation_level": 70}
)

print(result.instance_id)  # wfi_abc123
print(result.initial_phase)  # static_analysis
```

### 3. æ¨è¿›å·¥ä½œæµï¼ˆæ”¯æŒ Dry Runï¼‰
```python
# æ­£å¸¸æ¨è¿›
state = engine.trigger_next_step(
    instance_id=result.instance_id,
    trigger_data={"issues_found": 5},
    meta={"duration_sec": 12.5}
)

# Dry Run é¢„æ¼”
preview_state = engine.trigger_next_step(
    instance_id=result.instance_id,
    trigger_data={"issues_found": 50},  # å‡è®¾å‘ç°å¤§é‡é—®é¢˜
    dry_run=True  # ä¸ä¿å­˜çŠ¶æ€
)

print(preview_state.current_phase)  # å¯èƒ½æ˜¯ "manual_review" è€Œé "ai_review"
```

### 4. æŸ¥è¯¢çŠ¶æ€ï¼ˆå¤šå±‚çº§ï¼‰
```python
# è·å–ç²¾ç®€çŠ¶æ€ï¼ˆæ¨èç”¨äºUIæ˜¾ç¤ºï¼‰
status_info = engine.get_workflow_status_info("wfi_abc123")
# {'instance_id': 'wfi_abc123', 'status': 'running', 'progress': 0.4, ...}

# è·å–å®Œæ•´çŠ¶æ€ï¼ˆç”¨äºè°ƒè¯•ï¼‰
full_state = engine.get_workflow_state("wfi_abc123")

# è·å–å®¡è®¡å†å²
history = engine.get_workflow_history("wfi_abc123")
# [HistoryEntry(event_type="phase_started", ...), ...]
```

### 5. è·å–ç‰¹æ€§èšåˆçŠ¶æ€
```python
feature_status = engine.get_feature_status("feat_pr_123")
# {'total_instances': 1, 'running_count': 1, 'status': 'in_progress', ...}
```

---

## ğŸ“¦ å­˜å‚¨ç›®å½•ç¤ºä¾‹
```
.my_project/
â””â”€â”€ .chatflow/
    â”œâ”€â”€ schemas/
    â”‚   â””â”€â”€ code_review.yaml
    â”œâ”€â”€ instances/
    â”‚   â”œâ”€â”€ wfi_abc123.json              # ç²¾ç®€çŠ¶æ€ (StatusInfo)
    â”‚   â””â”€â”€ wfi_abc123/
    â”‚       â”œâ”€â”€ full_state.json          # å®Œæ•´çŠ¶æ€ (State)
    â”‚       â”œâ”€â”€ history.ndjson           # äº‹ä»¶æµ
    â”‚       â””â”€â”€ tasks/
    â”‚           â””â”€â”€ static_analysis.json
    â”œâ”€â”€ features/
    â”‚   â””â”€â”€ feat_pr_123.link
    â”œâ”€â”€ .indexes/
    â”‚   â””â”€â”€ feature_index.json
    â””â”€â”€ .locks/
```

---

## âœ… v1.1 å…³é”®ä¼˜åŠ¿æ€»ç»“

| ç‰¹æ€§ | ç”¨æˆ·ä»·å€¼ |
|------|----------|
| **Schema éªŒè¯** | é…ç½®é”™è¯¯æå‰æš´éœ²ï¼Œé¿å…æ‰§è¡Œä¸­æ–­ |
| **Dry Run** | å®‰å…¨é¢„æ¼”æµç¨‹ï¼Œæå‡è°ƒè¯•æ•ˆç‡ |
| **ä¸‰é‡çŠ¶æ€** | UIå¿«ã€å®¡è®¡å…¨ã€å†…å­˜ä¼˜ |
| **æ¡ä»¶åˆ†æ”¯** | æµç¨‹æ™ºèƒ½ï¼Œæ ¹æ®ä¸Šä¸‹æ–‡è‡ªé€‚åº” |
| **æ¸è¿›è‡ªåŠ¨åŒ–** | é£é™©å¯æ§ï¼ŒäººæœºååŒ |
| **å®Œæ•´å†å²** | å…¨é“¾è·¯è¿½è¸ªï¼Œæ”¯æŒå›æº¯åˆ†æ |

æ­¤æ¡†æ¶åœ¨ **ä»…å¢åŠ çº¦150è¡Œæ ¸å¿ƒä»£ç ** çš„å‰æä¸‹ï¼Œå°† ChatFlow ä»â€œçŠ¶æ€è®°å½•å™¨â€å‡çº§ä¸ºâ€œå¯ä¿¡å†³ç­–å¼•æ“â€ï¼Œå®Œç¾å¹³è¡¡äº†è½»é‡ä¸å¼ºå¤§ã€‚
